{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DP1e-5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxrjTQzCDWPx",
        "outputId": "b4f80a41-58c8-4e48-9a9b-b2d882feeb25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ChrisWaites/pyvacy\n",
            "  Cloning https://github.com/ChrisWaites/pyvacy to /tmp/pip-req-build-ds0n7zat\n",
            "  Running command git clone -q https://github.com/ChrisWaites/pyvacy /tmp/pip-req-build-ds0n7zat\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pyvacy==0.0.1) (1.10.0+cu111)\n",
            "Collecting torch-vision\n",
            "  Downloading torch_vision-0.1.6.dev0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pyvacy==0.0.1) (3.10.0.2)\n",
            "Building wheels for collected packages: pyvacy\n",
            "  Building wheel for pyvacy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyvacy: filename=pyvacy-0.0.1-py3-none-any.whl size=13541 sha256=15a58a48bd21f4bdce0ed06850f4ef6ca2733ae69f17cf464c34b6805aa1dd74\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-35gtvi1e/wheels/40/eb/29/76f7941eb0c1fd78c6c738d1c7bde62b3cd8cbf364ad1686a3\n",
            "Successfully built pyvacy\n",
            "Installing collected packages: torch-vision, pyvacy\n",
            "Successfully installed pyvacy-0.0.1 torch-vision-0.1.6.dev0\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install git+https://github.com/ChrisWaites/pyvacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets \n",
        "from tqdm.notebook import tqdm\n",
        "from torchvision import datasets, transforms, models \n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data.dataloader import DataLoader"
      ],
      "metadata": {
        "id": "KoMTHyhDMpXJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from pyvacy import optim, analysis\n",
        "\n",
        "\n",
        "# Deterministic output\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, inp):\n",
        "        return inp.reshape(inp.shape[0], -1)\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim,device='cpu'):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.conv1 =torch.nn.Conv2d(3, 32, 3, 1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, 3, 1) \n",
        "        self.dropout = torch.nn.Dropout2d(0.25)\n",
        "        self.fc1 = torch.nn.Linear(147456, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.functional.relu(self.conv1(x))\n",
        "        x = torch.nn.functional.relu(self.conv2(x))\n",
        "        x = torch.nn.functional.max_pool2d(x, 2)\n",
        "        x = self.dropout(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = torch.nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(self.dropout(x))\n",
        "        output = torch.nn.functional.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "   \n"
      ],
      "metadata": {
        "id": "esT0jhJvDe_X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxh9ksXGEGGD",
        "outputId": "3c438787-bd3d-4c05-d3bd-59c66ddc528a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvacy import optim, analysis, sampling"
      ],
      "metadata": {
        "id": "L5Cc65ZdET-8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('/content/drive/MyDrive/archive.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()"
      ],
      "metadata": {
        "id": "FNV7mjxJDnKX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "train_dir = '/content/train'\n",
        "val_dir = '/content/val'\n",
        "test_dir = '/content/val'\n",
        "classes = os.listdir(train_dir)\n",
        "print(classes)\n",
        "print(len(classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "621V1k7dFKmS",
        "outputId": "fc091778-76c1-44e5-e1e2-2372630b42cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['TURBERCULOSIS', 'COVID19', 'NORMAL', 'PNEUMONIA']\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform=transforms.Compose([\n",
        "        transforms.RandomRotation(10),      # rotate +/- 10 degrees\n",
        "        transforms.RandomHorizontalFlip(),  # reverse 50% of images\n",
        "        transforms.Resize(100),             # resize shortest side\n",
        "        transforms.CenterCrop(100),         # crop longest side\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "def train(params):\n",
        "  \n",
        "  trainset = ImageFolder(train_dir, transform=train_transform)\n",
        "  valset = ImageFolder(val_dir, transform=train_transform)\n",
        "  testset = ImageFolder(test_dir, transform=train_transform)\n",
        "  train_ds, val_ds, test_ds = trainset, valset, testset\n",
        "  train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "  val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
        "  test_loader = DataLoader(test_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
        "\n",
        "\n",
        "  classifier = Classifier(input_dim=np.prod(trainset[0][0].shape),device=params['device'])\n",
        "\n",
        "  optimizer = optim.DPSGD(\n",
        "      l2_norm_clip=params['l2_norm_clip'],\n",
        "      noise_multiplier=params['noise_multiplier'],\n",
        "      params=classifier.parameters(),\n",
        "      lr=params['lr'],\n",
        "      weight_decay=params['l2_penalty'],\n",
        "      minibatch_size=params['minibatch_size'],\n",
        "      microbatch_size=params['microbatch_size'],\n",
        "      \n",
        "      )\n",
        "  loss_function = nn.NLLLoss()\n",
        "  minibatch_loader, microbatch_loader = sampling.get_data_loaders(\n",
        "    params['minibatch_size'],\n",
        "    params['microbatch_size'],\n",
        "    params['iterations']\n",
        "    )\n",
        "  iteration = 0\n",
        "  for X_minibatch, y_minibatch in minibatch_loader(trainset):\n",
        "        optimizer.zero_grad()\n",
        "        for X_microbatch, y_microbatch in microbatch_loader(TensorDataset(X_minibatch, y_minibatch)):\n",
        "            X_microbatch = X_microbatch.to(params['device'])\n",
        "            y_microbatch = y_microbatch.to(params['device'])\n",
        "\n",
        "            #optimizer.zero_microbatch_grad()\n",
        "            loss = loss_function(classifier(X_microbatch), y_microbatch)\n",
        "            loss.backward()\n",
        "            #optimizer.microbatch_step()\n",
        "        optimizer.step()\n",
        "\n",
        "        if iteration % 10 == 0:\n",
        "            print('[Iteration %d/%d] [Loss: %f]' % (iteration, params['iterations'], loss.item()))\n",
        "        iteration += 1\n",
        "  return classifier\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "Wy2rvP9mET5O"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.argv=['']\n",
        "del sys"
      ],
      "metadata": {
        "id": "TeadYkqwMcZi"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " testset = ImageFolder(test_dir, transform=train_transform)"
      ],
      "metadata": {
        "id": "ixoltwQ1OPwL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--delta', type=float, default=1e-5, help='delta for epsilon calculation (default: 1e-5)')\n",
        "    parser.add_argument('--device', type=str, default=('cuda' if torch.cuda.is_available() else 'cpu'), help='whether or not to use cuda (default: cuda if available)')\n",
        "    parser.add_argument('--iterations', type=int, default=10, help='number of iterations to train (default: 14000)')\n",
        "    parser.add_argument('--l2-norm-clip', type=float, default=1., help='upper bound on the l2 norm of gradient updates (default: 0.1)')\n",
        "    parser.add_argument('--l2-penalty', type=float, default=0.001, help='l2 penalty on model weights (default: 0.001)')\n",
        "    parser.add_argument('--lr', type=float, default=0.15, help='learning rate (default: 0.15)')\n",
        "    parser.add_argument('--microbatch-size', type=int, default=1, help='input microbatch size for training (default: 1)')\n",
        "    parser.add_argument('--minibatch-size', type=int, default=256, help='input minibatch size for training (default: 256)')\n",
        "    parser.add_argument('--noise-multiplier', type=float, default=1.1, help='ratio between clipping bound and std of noise applied to gradients (default: 1.1)')\n",
        "    params = vars(parser.parse_args())\n",
        "\n",
        "    classifier = train(params)\n",
        "\n",
        "    with open('dp_classifier.dat', 'wb') as f:\n",
        "        torch.save(classifier, f)\n",
        "\n",
        "\n",
        "    X, y = next(iter(DataLoader(testset)))\n",
        "    # X, y  = X.to('cuda'), y.to('cuda')\n",
        "\n",
        "    y_pred = classifier(X).max(1)[1]\n",
        "\n",
        "    count = 0.\n",
        "    correct = 0.\n",
        "    for pred, actual in zip(y_pred, y):\n",
        "        if pred.item() == actual.item():\n",
        "            correct += 1.\n",
        "        count += 1.\n",
        "    print('Test Accuracy: {}'.format(correct / count))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdOMYJzkET7_",
        "outputId": "61856acf-4da6-4656-d640-f4c8a4ba1219"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Iteration 0/10] [Loss: 1.351786]\n",
            "Test Accuracy: 0.0\n"
          ]
        }
      ]
    }
  ]
}